# %% [markdown]
# # Hola &#x1F600;,
# 
# Soy **Hesus Garcia** ‚Äì **"Soy el √∫nico Hesus que conoces (y probablemente conocer√°s) üåü"** ‚Äì S√≠, como "Jes√∫s", pero con una H que me hace √∫nico. Puede sonar raro, pero cr√©eme, ¬°no lo olvidar√°s! Como tu revisor en Triple-Ten, estoy aqu√≠ para guiarte y ayudarte a mejorar tu c√≥digo. Si algo necesita un ajuste, no hay de qu√© preocuparse; ¬°aqu√≠ estoy para hacer que tu trabajo brille con todo su potencial! ‚ú®
# 
# Cada vez que encuentre un detalle importante en tu c√≥digo, te lo se√±alar√© para que puedas corregirlo y as√≠ te prepares para un ambiente de trabajo real, donde el l√≠der de tu equipo actuar√≠a de manera similar. Si en alg√∫n momento no logras solucionar el problema, te dar√© m√°s detalles para ayudarte en nuestra pr√≥xima oportunidad de revisi√≥n.
# 
# Es importante que cuando encuentres un comentario, **no los muevas, no los modifiques, ni los borres**.
# 
# ---
# 
# ### Formato de Comentarios
# 
# Revisar√© cuidadosamente cada implementaci√≥n en tu notebook para asegurar que cumpla con los requisitos y te dar√© comentarios de acuerdo al siguiente formato:
# 
# 
# <div class="alert alert-block alert-success">
# <b>Comentario del revisor</b> <a class="tocSkip"></a><br>
#     
# <b>√âxito</b> - ¬°Excelente trabajo! Esta parte est√° bien implementada y contribuye significativamente al an√°lisis de datos o al proyecto. Contin√∫a aplicando estas buenas pr√°cticas en futuras secciones.
#     
# </div>
# 
# <div class="alert alert-block alert-warning">
# <b>Comentario del revisor</b> <a class="tocSkip"></a><br>
#     
# <b>Atenci√≥n</b> ‚ö†Ô∏è - Este c√≥digo est√° correcto, pero se puede optimizar. Considera implementar mejoras para que sea m√°s eficiente y f√°cil de leer. Esto fortalecer√° la calidad de tu proyecto.
#     
# </div>
# 
# <div class="alert alert-block alert-danger">
# <b>Comentario del revisor</b> <a class="tocSkip"></a><br>
#     
# <b>A resolver</b> ‚ùó - Aqu√≠ hay un problema o error en el c√≥digo que es necesario corregir para aprobar esta secci√≥n. Por favor, revisa y corrige este punto, ya que es fundamental para la validez del an√°lisis y la precisi√≥n de los resultados.
#     
# </div>
# 
# ---
# 
# Al final de cada revisi√≥n, recibir√°s un **Comentario General del Revisor** que incluir√°:
# 
# - **Aspectos positivos:** Un resumen de los puntos fuertes de tu proyecto.
# - **√Åreas de mejora:** Sugerencias sobre aspectos donde puedes mejorar.
# - **Temas adicionales para investigar:** Ideas de temas opcionales que puedes explorar por tu cuenta para desarrollar a√∫n m√°s tus habilidades.
# 
# Estos temas adicionales no son obligatorios en esta etapa, pero pueden serte √∫tiles para profundizar en el futuro.
# 
# ---
# 
# 
# Esta estructura en vi√±etas facilita la lectura y comprensi√≥n de cada parte del comentario final.
# 
# Tambi√©n puedes responderme de la siguiente manera si tienes alguna duda o quieres aclarar algo espec√≠fico:
# 
# 
# <div class="alert alert-block alert-info">
# <b>Respuesta del estudiante</b> <a class="tocSkip"></a>
#     
# Aqu√≠ puedes escribir tu respuesta o pregunta sobre el comentario.
#     
# </div>
# 
# 
# **¬°Empecemos!** &#x1F680;
# 

# %% [markdown]
# # Analisis para Interconect (Telecom/Prevencion de Churn)

# %% [markdown]
# ## Descripcion del problema

# %% [markdown]
# Al operador de telecomunicaciones Interconnect le gustar√≠a poder pronosticar su tasa de cancelaci√≥n de clientes. 
# Si se descubre que un usuario o usuaria planea irse, se le ofrecer√°n c√≥digos promocionales y opciones de planes especiales. El equipo de marketing de Interconnect ha recopilado algunos de los datos personales de sus clientes, incluyendo informaci√≥n sobre sus planes y contratos.
# 
# ### Servicios de Interconnect
# 
# Interconnect proporciona principalmente dos tipos de servicios:
# 
# 1. Comunicaci√≥n por tel√©fono fijo. El tel√©fono se puede conectar a varias l√≠neas de manera simult√°nea.
# 2. Internet. La red se puede configurar a trav√©s de una l√≠nea telef√≥nica (DSL, *l√≠nea de abonado digital*) o a trav√©s de un cable de fibra √≥ptica.
# 
# Algunos otros servicios que ofrece la empresa incluyen:
# 
# - Seguridad en Internet: software antivirus (*Protecci√≥nDeDispositivo*) y un bloqueador de sitios web maliciosos (*SeguridadEnL√≠nea*).
# - Una l√≠nea de soporte t√©cnico (*SoporteT√©cnico*).
# - Almacenamiento de archivos en la nube y backup de datos (*BackupOnline*).
# - Streaming de TV (*StreamingTV*) y directorio de pel√≠culas (*StreamingPel√≠culas*)
# 
# La clientela puede elegir entre un pago mensual o firmar un contrato de 1 o 2 a√±os. Puede utilizar varios m√©todos de pago y recibir una factura electr√≥nica despu√©s de una transacci√≥n.
# 
# ### Descripci√≥n de los datos
# 
# Los datos consisten en archivos obtenidos de diferentes fuentes:
# 
# - `contract.csv` ‚Äî informaci√≥n del contrato;
# - `personal.csv` ‚Äî datos personales del cliente;
# - `internet.csv` ‚Äî informaci√≥n sobre los servicios de Internet;
# - `phone.csv` ‚Äî informaci√≥n sobre los servicios telef√≥nicos.
# 
# En cada archivo, la columna `customerID` (ID de cliente) contiene un c√≥digo √∫nico asignado a cada cliente. La informaci√≥n del contrato es v√°lida a partir del 1 de febrero de 2020.

# %% [markdown]
# ## Inicializacion

# %% [markdown]
# ### Carga de librerias

# %%
import pandas as pd
import numpy as np

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV

import sklearn.metrics as metrics
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score

from sklearn.utils import shuffle

from sklearn.dummy import DummyClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from catboost import CatBoostClassifier

import lightgbm as lgb

import matplotlib.pyplot as plt
import seaborn as sns


#from sklearn.datasets import make_classification


# %% [markdown]
# ### Variables

# %%
validation_size = 0.25

# %% [markdown]
# <div class="alert alert-block alert-success"> <b>Comentario del revisor</b> <a class="tocSkip"></a><br> <b>√âxito</b> - Buena selecci√≥n y organizaci√≥n de librer√≠as, cubriendo desde la manipulaci√≥n de datos hasta el modelado y visualizaci√≥n. Una base s√≥lida para el desarrollo del proyecto.</div>
# 

# %% [markdown]
# ## Funciones

# %%
"""
 Analiza si el customerID se encuentra mas de una vez en el data set lo que implicar√≠a que es una relacion 1:n
"""
def analizaDatosLlave(df):
    customer_counts = df['customerID'].value_counts()
    duplicate_ids = customer_counts[customer_counts > 1].index.tolist()
    
    print("customerIDs que aparecen m√°s de una vez:", duplicate_ids)
    print("-" * 30)

# %%

def generaGraficaCorr(data):
    # Graficando la correlacion entre variables numericas Posterior a la estandarizacion 
    corr = data.corr()  # Calculate the correlation matrix
    sns.heatmap(corr, annot=False, cmap='coolwarm')  # Create a heatmap
    plt.show()

# %%
def displayClassFrequency(y_train):
    class_frequency = y_train.value_counts(normalize=True)
    print("Normalized Class Frequency:")
    print(class_frequency)
    class_frequency.plot(kind='bar')

# %%
# A function to generate oversampling
def generate_oversamples(features, target, nrepeat):

    if (target[target == 0].count()<target[target == 1].count()):
        target_minority_class = target[target == 0]
        target_majority_class = target[target == 1]
        features_minority_class = features[target == 0]
        features_majority_class = features[target == 1]
    else:
        target_minority_class = target[target == 1]
        target_majority_class = target[target == 0]
        features_minority_class = features[target == 1]
        features_majority_class = features[target == 0]

    diff = 0
    if(nrepeat==0):
        nrepeat = int(target_majority_class.count()/target_minority_class.count())
        diff = target_majority_class.count() % target_minority_class.count()

    features_upsampled = pd.concat(
        [features_majority_class] + 
        [features_minority_class] * nrepeat 
    )
    
    target_upsampled = pd.concat(
        [target_majority_class] + 
        [target_minority_class] * nrepeat 
    )

    if diff>0:
        features_upsampled = pd.concat(
            [features_upsampled] + [features_minority_class.sample(diff, random_state=12345)]
        )
        target_upsampled = pd.concat(
            [target_upsampled] + [target_minority_class.sample(diff, random_state=12345)]
        )
        

    features_upsampled, target_upsampled = shuffle(
        features_upsampled, target_upsampled, random_state=12345
    )

    return features_upsampled, target_upsampled

# %%
# A function to generate a undersampling
def undersample(features, target, fraction):
    features_zeros = features[target == 0]
    features_ones = features[target == 1]
    target_zeros = target[target == 0]
    target_ones = target[target == 1]

    if(target_zeros.count()>target_ones.count()):
        features_downsampled = pd.concat(
            [features_zeros.sample(frac=fraction, random_state=12345)]+[features_ones]
        )
        target_downsampled = pd.concat(
            [target_zeros.sample(frac=fraction, random_state=12345)]+[target_ones]
        )
    else:
        features_downsampled = pd.concat(
            [features_ones.sample(frac=fraction, random_state=12345)]+[features_zeros]
        )
        target_downsampled = pd.concat(
            [features_ones.sample(frac=fraction, random_state=12345)]+[features_zeros]
        )

    features_downsampled, target_downsampled = shuffle(
        features_downsampled, target_downsampled, random_state=12345
    )

    return features_downsampled, target_downsampled

# %%
def selectBestModel(features_train, target_train, strategy_label):
    best_score = 0
    the_best_model = {}
    for model_name, model in models.items():
        model_grid_params = grid_params[model_name]
        search = GridSearchCV(model,
                              #scoring='f1',
                              scoring='roc_auc',
                              param_grid=model_grid_params,
                              cv=5,
                              n_jobs=-1)
        search.fit(features_train, target_train)

        if search.best_score_ > best_score:
            the_best_model["strategy_label"] = strategy_label
            the_best_model["best_estimator"] = search.best_estimator_
            the_best_model["best_score"] = search.best_score_
            the_best_model["best_params"] = search.best_params_
            best_score = search.best_score_

    return the_best_model

# %%
def evaluate_model(model, train_features, train_target, test_features, test_target):
    
    eval_stats = {}
    
    fig, axs = plt.subplots(1, 3, figsize=(20, 6)) 
    
    for type, features, target in (('train', train_features, train_target), ('test', test_features, test_target)):
        
        eval_stats[type] = {}
    
        pred_target = model.predict(features)
        pred_proba = model.predict_proba(features)[:, 1]
        
        # F1
        f1_thresholds = np.arange(0, 1.01, 0.05)
        f1_scores = [metrics.f1_score(target, pred_proba>=threshold) for threshold in f1_thresholds]
        
        # ROC
        fpr, tpr, roc_thresholds = metrics.roc_curve(target, pred_proba)
        roc_auc = metrics.roc_auc_score(target, pred_proba)    
        eval_stats[type]['ROC AUC'] = roc_auc

        # PRC
        precision, recall, pr_thresholds = metrics.precision_recall_curve(target, pred_proba)
        aps = metrics.average_precision_score(target, pred_proba)
        eval_stats[type]['APS'] = aps
        
        if type == 'train':
            color = 'blue'
        else:
            color = 'green'

        # Valor F1
        ax = axs[0]
        max_f1_score_idx = np.argmax(f1_scores)
        ax.plot(f1_thresholds, f1_scores, color=color, label=f'{type}, max={f1_scores[max_f1_score_idx]:.2f} @ {f1_thresholds[max_f1_score_idx]:.2f}')
        # establecer cruces para algunos umbrales        
        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):
            closest_value_idx = np.argmin(np.abs(f1_thresholds-threshold))
            marker_color = 'orange' if threshold != 0.5 else 'red'
            ax.plot(f1_thresholds[closest_value_idx], f1_scores[closest_value_idx], color=marker_color, marker='X', markersize=7)
        ax.set_xlim([-0.02, 1.02])    
        ax.set_ylim([-0.02, 1.02])
        ax.set_xlabel('threshold')
        ax.set_ylabel('F1')
        ax.legend(loc='lower center')
        ax.set_title(f'Valor F1') 

        # ROC
        ax = axs[1]    
        ax.plot(fpr, tpr, color=color, label=f'{type}, ROC AUC={roc_auc:.2f}')
        # establecer cruces para algunos umbrales        
        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):
            closest_value_idx = np.argmin(np.abs(roc_thresholds-threshold))
            marker_color = 'orange' if threshold != 0.5 else 'red'            
            ax.plot(fpr[closest_value_idx], tpr[closest_value_idx], color=marker_color, marker='X', markersize=7)
        ax.plot([0, 1], [0, 1], color='grey', linestyle='--')
        ax.set_xlim([-0.02, 1.02])    
        ax.set_ylim([-0.02, 1.02])
        ax.set_xlabel('False Positive Rate')
        ax.set_ylabel('True Positive Rate')
        ax.legend(loc='lower center')        
        ax.set_title(f'Curva ROC')
        
        # PRC
        ax = axs[2]
        ax.plot(recall, precision, color=color, label=f'{type}, AP={aps:.2f}')
        # establecer cruces para algunos umbrales        
        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):
            closest_value_idx = np.argmin(np.abs(pr_thresholds-threshold))
            marker_color = 'orange' if threshold != 0.5 else 'red'
            ax.plot(recall[closest_value_idx], precision[closest_value_idx], color=marker_color, marker='X', markersize=7)
        ax.set_xlim([-0.02, 1.02])    
        ax.set_ylim([-0.02, 1.02])
        ax.set_xlabel('recall')
        ax.set_ylabel('precision')
        ax.legend(loc='lower center')
        ax.set_title(f'PRC')        
        
        eval_stats[type]['Accuracy'] = metrics.accuracy_score(target, pred_target)
        eval_stats[type]['F1'] = metrics.f1_score(target, pred_target)
    
    df_eval_stats = pd.DataFrame(eval_stats)
    df_eval_stats = df_eval_stats.round(2)
    df_eval_stats = df_eval_stats.reindex(index=('Exactitud', 'F1', 'APS', 'ROC AUC'))
    
    print(df_eval_stats)
    
    return

# %% [markdown]
# <div class="alert alert-block alert-success"> <b>Comentario del revisor</b> <a class="tocSkip"></a><br> <b>√âxito</b> - Muy buena implementaci√≥n de funciones clave para el an√°lisis y evaluaci√≥n de modelos, con una estructura clara que cubre desde la exploraci√≥n de datos hasta m√©tricas avanzadas de desempe√±o.</div>
# 

# %% [markdown]
# ## Carga de datos

# %%
df_contract = pd.read_csv("/datasets/final_provider/contract.csv")
df_personal = pd.read_csv("/datasets/final_provider/personal.csv")
df_internet = pd.read_csv("/datasets/final_provider/internet.csv")
df_phone = pd.read_csv("/datasets/final_provider/phone.csv")

# %% [markdown]
# <div class="alert alert-block alert-success"> <b>Comentario del revisor</b> <a class="tocSkip"></a><br> <b>√âxito</b> - Correcta carga de los datasets necesarios, estableciendo una base ordenada para el an√°lisis posterior.</div>
# 

# %% [markdown]
# ## Analisis Exploratorio de Datos (EDA)

# %% [markdown]
# ### Contracts (dataset)

# %%
df_contract.info()

# %%
df_contract.sample(15)

# %%
df_contract.drop_duplicates().info()

# %%
df_contract.describe()

# %%
df_contract["BeginDate"].unique()

# %%
df_contract[df_contract["BeginDate"]>="2020-01-01"]["BeginDate"].value_counts()

# %%
df_contract[df_contract["EndDate"]>="2020-01-01"]["EndDate"].value_counts()

# %%
print(df_contract['Type'].sort_values().unique())
print(df_contract['PaperlessBilling'].sort_values().unique())
print(df_contract['PaymentMethod'].sort_values().unique())
print(df_contract['EndDate'].sort_values().unique())

# %%
# Convertir la serie a num√©rica con manejo de errores
s_numeric = pd.to_numeric(df_contract["TotalCharges"], errors='coerce')

# Verificar si hay valores NaN (no num√©ricos)
has_non_numeric = s_numeric.isna().any()

print("\n¬øContiene la serie valores no num√©ricos (NaN)?", has_non_numeric)

# %%
df_contract[s_numeric.isna()]["TotalCharges"].value_counts()

# %%
df_contract[s_numeric.isna()].sample(11)

# %% [markdown]
# <div class="alert alert-block alert-success"> <b>Comentario del revisor</b> <a class="tocSkip"></a><br> <b>√âxito</b> - El an√°lisis exploratorio inicial es detallado, identificando tipos de datos, valores √∫nicos y casos at√≠picos como registros con `TotalCharges` vac√≠os, lo que demuestra un enfoque minucioso hacia la calidad de los datos.</div>
# 

# %% [markdown]
# ### Personal (dataset)

# %%
df_personal.info()

# %%
df_personal.sample(10)

# %%
df_personal.drop_duplicates().info()

# %%
analizaDatosLlave(df_personal)

# %% [markdown]
# <div class="alert alert-block alert-success"> <b>Comentario del revisor</b> <a class="tocSkip"></a><br> <b>√âxito</b> - Revisi√≥n correcta del dataset personal, confirmando integridad de registros y ausencia de duplicados en las llaves primarias.</div>
# 

# %% [markdown]
# ### Internet (dataset)

# %%
df_internet.info()

# %%
df_internet.sample(10)

# %%
analizaDatosLlave(df_internet)

# %%
df_internet["InternetService"].unique()

# %% [markdown]
# <div class="alert alert-block alert-success"> <b>Comentario del revisor</b> <a class="tocSkip"></a><br> <b>√âxito</b> - An√°lisis claro del dataset de internet, verificando unicidad de claves y distribuci√≥n de tipos de servicio, lo que prepara bien el terreno para integraciones posteriores.</div>
# 

# %% [markdown]
# ### Phone (dataset)

# %%
df_phone.info()

# %%
df_phone.sample(10)

# %%
df_phone["MultipleLines"].unique()

# %%
analizaDatosLlave(df_phone)

# %% [markdown]
# <div class="alert alert-block alert-success"> <b>Comentario del revisor</b> <a class="tocSkip"></a><br> <b>√âxito</b> - Correcta validaci√≥n de la estructura y valores del dataset telef√≥nico, confirmando que las llaves son √∫nicas y que la variable categ√≥rica est√° bien definida.</div>
# 

# %% [markdown]
# ## Entendiendo los datos y el problema

# %% [markdown]
# En cuanto al problema, se entiende que a partir de los datos muestra, se busca anticiparse a que un cliente cancele. 
# 
# Algunos asumptions a aclarar con el equipo:
# - Se manejar√° como variable objetivo la variable enddate del dataset contract
# - En caso de que esta tenga un valor indica que el cliente ya ha cancelado
# - El objetivo seria poder estimar la cancelacion de los clientes para poder cambiar su situacion y poder retenerlo
# - Se descartar√° la fecha del 2020-02-01. Aplicable a cualquiera de las caracteristicas (BeginDate, EndDate) resulta en mantener un minimo de datos lo que no apoyar√≠a al modelo.
# 
# Algunos comentarios a partir del EDA ya que es necesario realizar un preprocesamiento de datos:
# - Se deber√° incluir el manejo de variables categoricas y la normalizaci√≥n de datos
# - Se debe determinar si se descartan datos pues habr√° datos nulos al relacionar la informaci√≥n
# 
# 
# De lo anterior se sugieren las siguientes fases con los datos como plan de trabajo:

# %% [markdown]
# ## Preprocesamiento de datos

# %% [markdown]
# ### Tratamiento de dataset Contract

# %%
df_temp = df_contract.rename(columns={
        'customerID': 'customer_id', 
        'BeginDate': 'begin_date', 
        'EndDate': 'end_date', 
        'Type': 'type', 
        'PaperlessBilling': 'paperless_billing',
        'PaymentMethod': 'payment_method',
        'MonthlyCharges': 'monthly_charges',
        'TotalCharges': 'total_charges'
    })

# %%
df_temp['paperless_billing'] = pd.to_numeric(df_temp['paperless_billing'].replace({'Yes': 1, 'No': 0}), downcast="unsigned")
df_temp["monthly_charges"] = pd.to_numeric(df_temp["monthly_charges"], downcast="float")
df_temp['total_charges'] = pd.to_numeric(df_temp['total_charges'], errors="coerce", downcast="float")

# %%
df_temp["total_charges"] = df_temp["total_charges"].fillna(0)

# %%
df_temp[df_temp["end_date"] == 'No'].head()

# %%
df_temp["ceased_customer"] = pd.to_numeric((df_temp["end_date"]!='No').astype(int), downcast="unsigned")

# %%
df_temp.head()

# %%
df_temp = df_temp.drop(["begin_date", "end_date"], axis = 1)

# %%
df_temp.info()

# %% [markdown]
# <div class="alert alert-block alert-success"> <b>Comentario del revisor</b> <a class="tocSkip"></a><br> <b>√âxito</b> - Excelente planteamiento del problema y preprocesamiento inicial, creando la variable objetivo y dejando un dataset limpio y coherente para el modelado.</div>
# 

# %% [markdown]
# ### Tratamiento de dataset Personal

# %%
df_merged = pd.merge(df_temp, df_personal, left_on='customer_id', right_on='customerID', how='left', copy='False')

# %%
df_merged.info()

# %%
df_temp = df_merged.rename(
    columns={
        'SeniorCitizen': 'senior_citizen', 
        'Partner': 'partner', 
        'Dependents': 'dependents'
    })

# %%
df_temp = df_temp.drop(["customerID"], axis = 1)

# %%
df_temp['senior_citizen'] = pd.to_numeric(df_temp['senior_citizen'], downcast="unsigned")
df_temp['partner'] = pd.to_numeric(df_temp['partner'].replace({'Yes': 1, 'No': 0}), downcast="unsigned")
df_temp['dependents'] = pd.to_numeric(df_temp['dependents'].replace({'Yes': 1, 'No': 0}), downcast="unsigned")
df_temp['gender'] = pd.to_numeric(df_temp['gender'].replace({'Male': 1, 'Female': 0}), downcast="unsigned")

# %%
df_temp.info()

# %%
df_temp.describe()

# %% [markdown]
# <div class="alert alert-block alert-success"> <b>Comentario del revisor</b> <a class="tocSkip"></a><br> <b>√âxito</b> - Integraci√≥n correcta del dataset personal con el contractual, aplicando transformaciones y codificaciones limpias que dejan las variables listas para el an√°lisis y modelado.</div>
# 

# %% [markdown]
# ### Tratamiento de dataset Internet

# %%
df_merged = pd.merge(df_temp, df_internet, left_on='customer_id', right_on='customerID', how='left', copy='False')

# %%
df_temp = df_merged.rename(
    columns={
        'InternetService': 'internet_service', 
        'OnlineSecurity': 'online_security', 
        'OnlineBackup': 'online_backup',
        'DeviceProtection': 'device_protection',
        'TechSupport': 'tech_support',
        'StreamingTV': 'streaming_tv',
        'StreamingMovies': 'streaming_movies'
    })

# %%
df_temp = df_temp.drop(["customerID"], axis=1)

# %%
df_temp["internet_service"] = df_temp["internet_service"].fillna("none") # Replace all NaN with "none"
df_temp["online_security"] = df_temp["online_security"].fillna(0)
df_temp["online_backup"] = df_temp["online_backup"].fillna(0)
df_temp["device_protection"] = df_temp["device_protection"].fillna(0)
df_temp["tech_support"] = df_temp["tech_support"].fillna(0)
df_temp["streaming_tv"] = df_temp["streaming_tv"].fillna(0)
df_temp["streaming_movies"] = df_temp["streaming_movies"].fillna(0)

# %%
df_temp['online_security'] = pd.to_numeric(df_temp['online_security'].replace({'Yes': 1, 'No': 0}), downcast="unsigned")
df_temp['online_backup'] = pd.to_numeric(df_temp['online_backup'].replace({'Yes': 1, 'No': 0}), downcast="unsigned")
df_temp['device_protection'] = pd.to_numeric(df_temp['device_protection'].replace({'Yes': 1, 'No': 0}), downcast="unsigned")
df_temp['tech_support'] = pd.to_numeric(df_temp['tech_support'].replace({'Yes': 1, 'No': 0}), downcast="unsigned")
df_temp['streaming_tv'] = pd.to_numeric(df_temp['streaming_tv'].replace({'Yes': 1, 'No': 0}), downcast="unsigned")
df_temp['streaming_movies'] = pd.to_numeric(df_temp['streaming_movies'].replace({'Yes': 1, 'No': 0}), downcast="unsigned")

# %%
df_temp.info()

# %% [markdown]
# <div class="alert alert-block alert-success"> <b>Comentario del revisor</b> <a class="tocSkip"></a><br> <b>√âxito</b> - Muy buena integraci√≥n y codificaci√≥n de variables del dataset de internet, manejando valores nulos de forma controlada y asegurando consistencia en el tipo de datos.</div>
# 

# %% [markdown]
# ### Tratamiento de dataset phone

# %%
df_merged = pd.merge(df_temp, df_phone, left_on='customer_id', right_on='customerID', how='left', copy='False')

# %%
df_merged.info()

# %%
df_temp = df_merged.rename(
    columns={
        'customerID': 'phone_service',    # Servir√° para indicar si tiene servicio de telefonia o no
        'MultipleLines': 'multiple_lines'
    })

# %%
df_temp["phone_service"] = df_temp["phone_service"].fillna(0)
df_temp["multiple_lines"] = df_temp["multiple_lines"].fillna(0)

# %%
df_temp["phone_service"] = df_temp['phone_service'].mask(df_temp['phone_service'] != 0, 1)

# %%
df_temp['phone_service'] = pd.to_numeric(df_temp['phone_service'], downcast="unsigned")
df_temp['multiple_lines'] = pd.to_numeric(df_temp['multiple_lines'].replace({"Yes":1, "No":0}), downcast="unsigned")

# %%
df_temp["phone_service"].value_counts()

# %%
df_temp["multiple_lines"].value_counts()

# %%
df_temp.info()

# %% [markdown]
# <div class="alert alert-block alert-success"> <b>Comentario del revisor</b> <a class="tocSkip"></a><br> <b>√âxito</b> - Integraci√≥n y codificaci√≥n del dataset telef√≥nico bien lograda, con un manejo adecuado de valores nulos y creaci√≥n de variables indicadoras que enriquecen el an√°lisis.</div>
# 

# %% [markdown]
# ### Visualizacion de resultado

# %%
df_temp.sample(10)

# %%
df_temp.describe()

# %% [markdown]
# <div class="alert alert-block alert-success"> <b>Comentario del revisor</b> <a class="tocSkip"></a><br> <b>√âxito</b> - El dataset final muestra una integraci√≥n completa y consistente, con todas las variables correctamente transformadas y listas para el an√°lisis y modelado.</div>
# 

# %% [markdown]
# ### Estandarizacion y normalizcion

# %%
cat_features = [
    'type', 
    'payment_method',
    'internet_service'
]

num_features = [
    'monthly_charges', 
    'total_charges'
]

data = df_temp.copy()

# %%
scaler = StandardScaler()
scaler.fit(data[num_features])
data[num_features] = scaler.transform(data[num_features])

# %%
data[num_features].describe()

# %%
# OneHotEncoder
data = pd.get_dummies(data, 
                      columns=cat_features, 
                     # drop_first=True
                     )

# %%
data.info()

# %%
data.head()

# %% [markdown]
# <div class="alert alert-block alert-success"> <b>Comentario del revisor</b> <a class="tocSkip"></a><br> <b>√âxito</b> - La estandarizaci√≥n de variables num√©ricas y la codificaci√≥n one-hot de categ√≥ricas est√°n bien aplicadas, dejando el dataset final en un formato √≥ptimo para el entrenamiento de modelos.</div>
# 

# %% [markdown]
# ### Seleccionando columnas finales

# %% [markdown]
# #### Grafica de correlacion

# %%
generaGraficaCorr(data)

# %% [markdown]
# <div class="alert alert-block alert-success"> <b>Comentario del revisor</b> <a class="tocSkip"></a><br> <b>√âxito</b> - La visualizaci√≥n de la matriz de correlaci√≥n permite una comprensi√≥n r√°pida de las relaciones entre variables, facilitando la detecci√≥n de posibles redundancias o patrones relevantes para el modelado.</div>
# 

# %% [markdown]
# #### Matriz de correlacion (Pearson)

# %%
matriz_correlacion = data.corr(method='pearson')

# %%
# Seleccionamos la columna 'variable_objetivo' para ver sus correlaciones con las dem√°s
correlaciones_con_objetivo = matriz_correlacion['ceased_customer']

print("Correlaci√≥n de cada caracter√≠stica con la variable objetivo:")
print(correlaciones_con_objetivo)

# %%
# Filtrando caracter√≠sticas bas√°ndose en un umbral
umbral = 0.05
caracteristicas_seleccionadas = correlaciones_con_objetivo[abs(correlaciones_con_objetivo) < umbral] #.index.tolist()

print(caracteristicas_seleccionadas)

# %% [markdown]
# #### Observaciones
# 
# Basado en el umbral, se opta por descartar las siguientes variables:

# %%
data = data.drop(["gender", 
                  #"online_backup", "device_protection",
                  #"streaming_tv", "streaming_movies",
#                  "phone_service", "multiple_lines",
                  #"payment_method_Mailed check"
                 ], axis = 1)
data = data.drop(["customer_id"], axis = 1)

# %%
data.duplicated().value_counts()

# %%
displayClassFrequency(data["ceased_customer"])

# %% [markdown]
# <div class="alert alert-block alert-success"> <b>Comentario del revisor</b> <a class="tocSkip"></a><br> <b>√âxito</b> - El an√°lisis de correlaciones est√° bien fundamentado y respalda la selecci√≥n de variables, manteniendo un dataset depurado y equilibrado para el modelado.</div>
# 

# %% [markdown]
# ## Generaci√≥n de un checkpoint

# %% [markdown]
# ### Almacenamiento de la informacion

# %%
# Almacenando el avance del trabajo de tratamiento de los datos en un archivo como checkpoint
try:
    data.to_parquet('interconnect.parquet')
except Exception as e:
    print(e)

# %% [markdown]
# ### Recuperaci√≥n de la informacion

# %%
# Se recupera la informacion desde el archivo donde fue almacenado un checkpoint
try:
    data = pd.read_parquet('interconnect.parquet') 
except Exception as e:
    print(e)

# %% [markdown]
# ## Segmentacion de datos

# %% [markdown]
# ### Separacion de features y target

# %%
y = data['ceased_customer']
X = data.drop('ceased_customer', axis=1)

# %% [markdown]
# ### Division de datos

# %%
X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=validation_size, random_state=10)

# %% [markdown]
# <div class="alert alert-block alert-success"> <b>Comentario del revisor</b> <a class="tocSkip"></a><br> <b>√âxito</b> - La segmentaci√≥n de datos y la separaci√≥n de variables se realiza de forma ordenada, dejando listo el conjunto de entrenamiento y validaci√≥n para el modelado.</div>
# 

# %% [markdown]
# ## Selecci√≥n y Evaluaci√≥n de Modelos

# %% [markdown]
# ### Definicion de modelos

# %%
# Define the models
models = {
    'DummyClassifier': DummyClassifier(random_state=54321),
    'LogisticRegression': LogisticRegression(random_state=54321),
    'DecisionTreeClassifier': DecisionTreeClassifier(random_state=54321),
    'RandomForestClassifier': RandomForestClassifier(random_state=54321),
    'LGBMClassifier': lgb.LGBMClassifier(objective='binary', random_state=54321),
    'CatBoost': CatBoostClassifier(loss_function='Logloss', eval_metric='AUC', verbose=False, random_seed=54321)
}

# Define the grid parameters for each model
grid_params = {
    "LogisticRegression": {
        "solver": ["liblinear", "lbfgs", "newton-cg"]  
    },
    "DummyClassifier":{
        "strategy": ['most_frequent']
    },
    'DecisionTreeClassifier': {
        'max_depth': [None, 10, 15, 20, 25, 30, 35, 40]
    },
    'RandomForestClassifier':{
        'n_estimators': [20, 30, 40, 50, 60, 70, 80, 90, 100],
        'class_weight': [None, 'balanced', 'balanced_subsample']
    },
    'LGBMClassifier': {
        'num_leaves': [30, 40], #  np.arange(20, 50, 10),  # N√∫mero de hojas en un √°rbol
        'learning_rate': [0.05],  # Tasa de aprendizaje
        'n_estimators': [150, 160, 170], #np.arange(50, 200, 50), # N√∫mero de √°rboles de refuerzo
        'max_depth': [-1, 5],  # Profundidad m√°xima del √°rbol (-1 significa sin l√≠mite)
        #'reg_alpha': [0, 0.1, 0.5, 1], # Regularizaci√≥n L1
        #'reg_lambda': [0, 0.1, 0.5, 1], # Regularizaci√≥n L2
        #'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0], # Submuestreo de columnas al construir cada √°rbol
        #'subsample': [0.6, 0.7, 0.8, 0.9, 1.0] # Submuestreo de datos al construir cada √°rbol
    },
    'CatBoost': {
        'iterations': [100, 200],
        'learning_rate': [0.05],
        'depth': [4, 5, 6]
    }
}

# %% [markdown]
# <div class="alert alert-block alert-success"> <b>Comentario del revisor</b> <a class="tocSkip"></a><br> <b>√âxito</b> - Buena definici√≥n del conjunto de modelos y configuraci√≥n de grids, con atenci√≥n al desbalance de clases para una evaluaci√≥n rigurosa.</div>
# 

# %% [markdown]
# ### Evaluando modelos

# %% [markdown]
# #### Clase objetivo desbalanceada (Imbalanced)

# %%
displayClassFrequency(y_train)

# %%
%%capture
the_best_model_dictionary = selectBestModel(X_train, y_train, "imbalanced")

# %%
print(the_best_model_dictionary)

# %%
model = the_best_model_dictionary["best_estimator"]
probabilities_one_train = model.predict_proba(X_train)[:, 1]
probabilities_one_valid = model.predict_proba(X_validation)[:, 1]
predicted_valid = model.predict(X_validation)

print("Precision score: {}".format(precision_score(y_validation, predicted_valid)))
print("Recall score:    {}".format(recall_score(y_validation, predicted_valid)))
print("F1 score:        {}".format(f1_score(y_validation, predicted_valid)))
print("ROC AUC Train score:   {}".format(roc_auc_score(y_train, probabilities_one_train)))
print("ROC AUC Test score:   {}".format(roc_auc_score(y_validation, probabilities_one_valid)))

# %%
evaluate_model(model, X_train, y_train, X_validation, y_validation)

# %%
fpr, tpr, thresholds = roc_curve(y_validation, probabilities_one_valid)

plt.figure()
plt.plot(fpr, tpr)
plt.plot([0, 1], [0, 1], linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC Curve')
plt.show()

# %% [markdown]
# #### Balanceando clase objetivo (Oversampling)

# %%
X_train_upsampled, y_train_upsampled = generate_oversamples(
    X_train, y_train, 0
)

# %%
displayClassFrequency(y_train_upsampled)

# %%
%%capture
the_best_model_dictionary = selectBestModel(X_train_upsampled, y_train_upsampled, "oversampling")

# %%
print(the_best_model_dictionary)

# %%
model = the_best_model_dictionary["best_estimator"]
probabilities_one_valid = model.predict_proba(X_validation)[:, 1]
predicted_valid = model.predict(X_validation)

print("Precision score: {}".format(precision_score(y_validation, predicted_valid)))
print("Recall score:    {}".format(recall_score(y_validation, predicted_valid)))
print("F1 score:        {}".format(f1_score(y_validation, predicted_valid)))
print("ROC AUC score:   {}".format(roc_auc_score(y_validation, probabilities_one_valid)))

# %%
evaluate_model(model, X_train_upsampled, y_train_upsampled, X_validation, y_validation)

# %%
fpr, tpr, thresholds = roc_curve(y_validation, probabilities_one_valid)

plt.figure()
plt.plot(fpr, tpr)
plt.plot([0, 1], [0, 1], linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC Curve')
plt.show()

# %% [markdown]
# <div class="alert alert-block alert-success"> <b>Comentario del revisor</b> <a class="tocSkip"></a><br> <b>√âxito</b> - La evaluaci√≥n de modelos incluye tanto escenarios con clases desbalanceadas como balanceadas, aplicando m√©tricas clave y comparando estrategias de forma estructurada para seleccionar la opci√≥n m√°s robusta.</div>
# 

# %% [markdown]
# ## Conclusiones Generales

# %% [markdown]
# Para el problema de Interconect se ha solicitado maximizar la metrica ROC-AUC. Es importante tener una buen desempe√±o con el modelo para tratar de predecir (incluso con la metrica de precision) cuando un cliente es suceptible a cancelar el servicio con la empresa, de esta forma se pueden tomar medidas de retenci√≥n de clientes y con ello reduccion de costos a largo plazo.
# 
# Este problema requiri√≥ un gran desarrollo en los diferentes aspectos para mejorar el desempe√±o de modelos. A continuaci√≥n se describen las acciones que se llevaron a cabo durante el proceso siguiendo con el plan a partir de un primer EDA.
# 
# - Tratamiento de los datos (preprocesamiento). Se consider√≥ la mejor calidad posible para los datos y llevandolos a una estandarizacion para la adecuada convivencia con los diferentes algoritmos disponibles.
# - Se utiliz√≥ la tectnica de wrapping (RFE) para descartar o mantener caracteristicas, esto se hizo en varias iteraciones (combinaciones) lo que indic√≥ que se tenia mayor beneficio para la metrica manteniendo la mayoria de las caracteristicas (basado en el umbral del coeficiente de correlacion).
# - Balanceo de clase objetivo. Se opt√≥ por utilizar oversampling preservando los datos y aumentando las muestras de la clase minoritaria. Dentro de esto mismo se realizaron pruebas equilibrando pruebas o solo aumentando la clase minoritaria.
# - Se prob√≥ tambien ajustando el tama√±o del set de datos para validacion (35%-25%)
# - En la evaluacion de modelos se incluyeron los siguientes algoritmos: RandomForest, LGBMClassifier, CatBoost y Regresi√≥n Log√≠stica, usando ROC-AUC como m√©trica. Se consider√≥ CatBoost en el conjunto de algoritmos evaluados debido a que es de los que manejan bien el desbalance de clases y las caracter√≠sticas categ√≥ricas.
# - Dentro de las pruebas se incluy√≥ igualmente el ajuste de hiperparametros tratando de mediar entre el mejor resultado y la optimizacion del modelo debido al poder de computo y tiempo requeridos.
# 
# Como seleccion final de los modelos se encontro el siguiente bajo los datos desbalanceados (datos originales) y que arroj√≥ un mejor equilibrio entre los datos de entrenamiento y de prueba:
# - 'best_estimator': catboost.core.CatBoostClassifier
# - ROC AUC Train score:   0.8722915954241087
# - ROC AUC Test score:   0.8404646900378719
# - 'best_params': {'depth': 4, 'iterations': 200, 'learning_rate': 0.05}
# 
# Finalmente, puedo decir que fue un reto el explorar todas las aristas posibles para lograr el mejor rendimiento del modelo seleccionado.

# %% [markdown]
# <div class="alert alert-block alert-success"> <b>Comentario del revisor</b> <a class="tocSkip"></a><br> <b>√âxito</b> - Conclusi√≥n bien estructurada que resume el flujo completo del proyecto, destacando las decisiones clave y respaldando la elecci√≥n final del modelo con m√©tricas s√≥lidas.</div>
# 

# %% [markdown]
# ## Comentario General del Revisor
# 
# <div class="alert alert-block alert-success"> <b>Comentario del revisor</b> <a class="tocSkip"></a>  
#     
# ¬°Felicidades! Tu proyecto est√° **aprobado**. Has desarrollado un flujo de trabajo completo y bien fundamentado que demuestra un dominio s√≥lido en el tratamiento de datos, la exploraci√≥n inicial, la preparaci√≥n para el modelado y la evaluaci√≥n de m√∫ltiples algoritmos.  
# 
# #### Puntos Positivos:
# 
# * **Procesamiento de datos:** Realizaste una limpieza exhaustiva, uniendo y transformando datasets de distintas fuentes con codificaci√≥n consistente, control de valores nulos y creaci√≥n precisa de la variable objetivo.
# * **An√°lisis exploratorio:** Tu EDA fue minucioso, identificando patrones relevantes y variables clave, adem√°s de detectar y tratar valores at√≠picos o inconsistencias.
# * **Ingenier√≠a de caracter√≠sticas:** Lograste codificar adecuadamente variables categ√≥ricas y estandarizar las num√©ricas, dejando la matriz de datos lista para un desempe√±o √≥ptimo de los modelos.
# * **Estrategias para el desbalance de clases:** Implementaste tanto escenarios con datos originales como oversampling, comparando impactos y eligiendo la estrategia m√°s coherente con el objetivo.
# * **Evaluaci√≥n de modelos:** Probaste m√∫ltiples algoritmos (RandomForest, LGBM, CatBoost, Regresi√≥n Log√≠stica, entre otros), afinaste hiperpar√°metros y seleccionaste el modelo con mejor equilibrio entre m√©tricas y generalizaci√≥n, priorizando ROC-AUC.
# * **Documentaci√≥n y conclusiones:** El cierre del proyecto explica claramente las decisiones t√©cnicas, el porqu√© de la elecci√≥n final y c√≥mo los resultados se alinean con los objetivos de negocio.
# 
# Has conseguido un pipeline robusto y replicable, con resultados consistentes tanto en entrenamiento como en validaci√≥n, y un an√°lisis que respalda cada decisi√≥n tomada. Este trabajo refleja un criterio anal√≠tico y t√©cnico muy bien desarrollado. </div>
# 

# %% [markdown]
# ## Informe final del proyecto

# %% [markdown]
# ### ¬øQu√© pasos del plan se realizaron y qu√© pasos se omitieron (explica por qu√©)?

# %% [markdown]
# - Se ejecutaron todos los pasos estipulados en el plan
# - En cambio, se agregaron algunos apartados a dicho plan para mejorar la organizacion del workbook as√≠ como puntos en donde el analisis nos forz√≥ a realizar medidas adicionales como la seccion de funciones/el manejo del checkpoint/manejo de seleccion de caracteristicas para mejorar el desempe√±o del modelo

# %% [markdown]
# ### ¬øQu√© dificultades encontraste y c√≥mo lograste resolverlas?

# %% [markdown]
# - Se implementaron los modelos basicos para un problema de clasificacion, sin embargo, no se conseguia el mejor rendimiento del modelo de acuerdo a la solicitud de negocio.

# %% [markdown]
# ### ¬øCu√°les fueron algunos de los pasos clave para resolver la tarea?

# %% [markdown]
# - Se definieron algoritmos adicionales para generar el modelo.
# - Se estuvo trabajando en la seleccion de caracteristicas, proporciones en la division de los datos y el manejo de hiperparametros.
# - Manejo y/o revision del balanceo de la clase objetivo.

# %% [markdown]
# ### ¬øCu√°l es tu modelo final y qu√© nivel de calidad tiene?

# %% [markdown]
# - ROC AUC Train score:   0.8722915954241087
# - ROC AUC Test score:   0.8404646900378719

# %% [markdown]
# 

# %%



